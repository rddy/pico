{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPdT-hYj1XXQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import uuid\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import numpy as np\n",
    "from brokenaxes import brokenaxes\n",
    "\n",
    "from pico.gan import PicoGAN\n",
    "from pico.user_models import ConvPolicy\n",
    "from pico.discrim_models import ConvDiscrim\n",
    "from pico.encoder_models import NVAEEncoder\n",
    "from pico.envs import CelebAEnv\n",
    "from pico.compression_models import Masker, ConvCompressor\n",
    "from pico import utils\n",
    "from pico import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = utils.make_tf_session(gpu_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task_idx = 15 # eyeglasses\n",
    "task_idx = 35 # hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(utils.celeba_data_dir, str(task_idx))\n",
    "if not os.path.exists(data_dir):\n",
    "  os.makedirs(data_dir)\n",
    "fig_dir = os.path.join(data_dir, 'figures')\n",
    "if not os.path.exists(fig_dir):\n",
    "  os.makedirs(fig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = utils.make_celeba_dataset(use_cache=True, task_idx=task_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_act_dims = dataset['n_classes']\n",
    "img_shape = dataset['img_shape']\n",
    "flat_img_size = 1\n",
    "for x in img_shape:\n",
    "  flat_img_size *= x\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder = NVAEEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_n_batches = 32\n",
    "bn_batch_size = 32\n",
    "bn_imgs = []\n",
    "for img_idx in range(0, bn_batch_size*bn_n_batches, bn_batch_size):\n",
    "  bn_img = dataset['imgs'][img_idx:img_idx+bn_batch_size]\n",
    "  bn_img = utils.front_img_ch(bn_img)\n",
    "  bn_img = bn_img.astype(float) / 255.\n",
    "  bn_img = utils.numpy_to_torch(bn_img).to('cuda')\n",
    "  bn_imgs.append(bn_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_imgs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_idxes = [i for i, x in enumerate(dataset['labels']) if x == 1]\n",
    "len(img_idxes) / len(dataset['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = dataset['imgs'][img_idxes[1]]\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = np.zeros((8, 8))\n",
    "#mask[3:5, :] = 1\n",
    "mask = mask.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "comp_img, kldiv = encoder.compress(img, mask, temp, bn_imgs=bn_imgs)\n",
    "kldiv, (time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(comp_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "  'obses': dataset['imgs'],\n",
    "  'actions': np.array([utils.onehot_encode(int(a), n_act_dims) for a in dataset['labels']])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = utils.split_user_data(data, train_frac=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_user_model_data_path = os.path.join(data_dir, 'sim_user_model_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sim_user_model_data_path, 'rb') as f:\n",
    "  data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sim_user_model_data_path, 'wb') as f:\n",
    "  pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_user_model_train_kwargs = {\n",
    "  'iterations': 2000,\n",
    "  'ftol': 1e-6,\n",
    "  'learning_rate': 5e-4,\n",
    "  'batch_size': 32,\n",
    "  'val_update_freq': 200,\n",
    "  'verbose': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_user_model = ConvPolicy(\n",
    "  sess, \n",
    "  n_act_dims=n_act_dims, \n",
    "  n_obs_dims=img_shape,\n",
    "  n_layers=2,\n",
    "  layer_size=256,\n",
    "  #scope=str(uuid.uuid4()),\n",
    "  scope_file=os.path.join(data_dir, 'sim_user_model_scope.pkl'),\n",
    "  tf_file=os.path.join(data_dir, 'sim_user_model.tf')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_user_model.train(data, **sim_user_model_train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_user_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_user_model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = data['train_idxes']\n",
    "env_data = {k: data[k][idxes] for k in ['obses', 'actions']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = 0.5\n",
    "def apply_mask(real_obs, obs_mask):\n",
    "  imgs = []\n",
    "  kldivs = []\n",
    "  for i in range(real_obs.shape[0]):\n",
    "    img, kldiv = encoder.compress(real_obs[i], obs_mask[i], temp, bn_imgs=bn_imgs)\n",
    "    imgs.append(img)\n",
    "    kldivs.append(kldiv)\n",
    "  return np.array(imgs), np.array(kldivs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_act_blocks = 8\n",
    "train_mask_limits = (0.25, 0.25)\n",
    "def make_env(val_mode=True):\n",
    "  rew_mod = ConvDiscrim(\n",
    "    sess, \n",
    "    n_act_dims=n_act_blocks,\n",
    "    n_obs_dims=img_shape,\n",
    "    n_layers=2,\n",
    "    layer_size=256,\n",
    "    scope=str(uuid.uuid4()),\n",
    "    scope_file=os.path.join(data_dir, 'rew_mod_scope.pkl'),\n",
    "    tf_file=os.path.join(data_dir, 'rew_mod.tf')\n",
    "  )\n",
    "  discrim = ConvDiscrim(\n",
    "    sess, \n",
    "    n_act_dims=n_act_dims,\n",
    "    n_obs_dims=img_shape,\n",
    "    struct=True,\n",
    "    n_layers=2,\n",
    "    layer_size=256,\n",
    "    scope=str(uuid.uuid4()),\n",
    "    scope_file=os.path.join(data_dir, 'discrim_scope.pkl'),\n",
    "    tf_file=os.path.join(data_dir, 'discrim.tf')\n",
    "  )\n",
    "  if not val_mode:\n",
    "    mask_limits = train_mask_limits\n",
    "  else:\n",
    "    mask_limits = (None, None)\n",
    "  env = CelebAEnv(\n",
    "    sim_user_model, \n",
    "    encoder, \n",
    "    env_data,\n",
    "    apply_mask,\n",
    "    rew_mod,\n",
    "    discrim,\n",
    "    val_mode=val_mode,\n",
    "    n_act_blocks=n_act_blocks,\n",
    "    mask_limits=mask_limits\n",
    "  )\n",
    "  return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(env, model_path):\n",
    "  if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "  model = ConvCompressor(\n",
    "    sess,\n",
    "    rew_mod=env.rew_mod,\n",
    "    n_obs_dims=img_shape,\n",
    "    n_act_dims=n_act_blocks,\n",
    "    n_user_act_dims=n_act_dims,\n",
    "    n_layers=2,\n",
    "    layer_size=256,\n",
    "    #scope=str(uuid.uuid4()),\n",
    "    scope_file=os.path.join(model_path, 'scope.pkl'),\n",
    "    tf_file=os.path.join(model_path, 'model.tf')\n",
    "  )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_kwargs = {\n",
    "  'iterations': 10000,\n",
    "  'ftol': 1e-6,\n",
    "  'learning_rate': 1e-3,\n",
    "  'batch_size': 32,\n",
    "  'val_update_freq': 1000,\n",
    "  'verbose': True\n",
    "}\n",
    "\n",
    "n_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew_mod_train_kwargs = {\n",
    "  'iterations': 2000,\n",
    "  'ftol': 1e-6,\n",
    "  'learning_rate': 1e-3,\n",
    "  'batch_size': 32,\n",
    "  'val_update_freq': 100,\n",
    "  'verbose': True\n",
    "}\n",
    "\n",
    "discrim_train_kwargs = {\n",
    "  'iterations': 2000,\n",
    "  'ftol': 1e-6,\n",
    "  'learning_rate': 1e-3,\n",
    "  'batch_size': 32,\n",
    "  'val_update_freq': 100,\n",
    "  'verbose': True\n",
    "}\n",
    "\n",
    "rew_mod_update_freq = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gan_training(model_path, using_mae=False):\n",
    "  env = make_env(val_mode=False)\n",
    "  model = make_model(env, model_path)\n",
    "  gan = PicoGAN(model, env)\n",
    "  model = gan.train(\n",
    "    model_train_kwargs, \n",
    "    verbose=False, \n",
    "    n_iter=n_iter,\n",
    "    rew_mod_update_freq=rew_mod_update_freq, \n",
    "    rew_mod_train_kwargs=rew_mod_train_kwargs,\n",
    "    discrim_train_kwargs=discrim_train_kwargs,\n",
    "    discrim_zero_val=0.25,\n",
    "    using_mae=using_mae\n",
    "  )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(data_dir, 'model_0')\n",
    "mae_model_path = os.path.join(data_dir, 'mae_model_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = NVAEEncoder()\n",
    "comp_img = encoder.compress(img, mask, temp, bn_imgs=bn_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = run_gan_training(\n",
    "  model_path=model_path, \n",
    "  using_mae=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_model = run_gan_training(\n",
    "  model_path=mae_model_path\n",
    "  using_mae=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = make_env(val_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "  model = make_model(eval_env, model_path)\n",
    "  model.load()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_model = load_model(mae_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def local_eval_model(compression_model, verbosity=0):\n",
    "  return utils.eval_model(\n",
    "    compression_model,\n",
    "    data,\n",
    "    encoder,\n",
    "    sim_user_model,\n",
    "    verbosity=verbosity\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = NVAEEncoder()\n",
    "comp_img = encoder.compress(img, mask, temp=temp, bn_imgs=bn_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_limit = 2/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mask_policy = lambda real_obses: np.random.random((real_obses.shape[0], eval_env.n_act_blocks))\n",
    "baseline_compression_model = Masker(baseline_mask_policy, eval_env, mask_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline_metrics = local_eval_model(baseline_compression_model, verbosity=20)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_mask_policy = model.act\n",
    "learned_compression_model = Masker(learned_mask_policy, eval_env, mask_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_metrics = local_eval_model(learned_compression_model, verbosity=20)\n",
    "learned_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_mask_policy = mae_model.act\n",
    "mae_compression_model = Masker(mae_mask_policy, eval_env, mask_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_metrics = local_eval_model(mae_compression_model, verbosity=20)\n",
    "mae_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_limits = np.arange(0, 1+1/n_act_blocks, 1/n_act_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask_policy_of_model = {\n",
    "  'baseline': baseline_mask_policy,\n",
    "  'mae': mae_mask_policy,\n",
    "  'learned': learned_mask_policy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_mask_policy(mask_policy, mask_limit, **kwargs):\n",
    "  compression_model = Masker(mask_policy, eval_env, mask_limit)\n",
    "  metrics = local_eval_model(compression_model)\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mets_of_model = viz.sweep_mask_limits(\n",
    "  mask_limits, \n",
    "  eval_env,\n",
    "  mask_policy_of_model,\n",
    "  eval_mask_policy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mets_path = os.path.join(data_dir, 'mets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mets_path, 'rb') as f:\n",
    "  mets_of_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mets_path, 'wb') as f:\n",
    "  pickle.dump(mets_of_model, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('CelebA Faces')\n",
    "plt.xlabel('Bitrate (Bits)')\n",
    "plt.ylabel(\"User's Action Agreement\")\n",
    "y_key = 'act_acc'\n",
    "x_key = 'kldiv'\n",
    "configs = [\n",
    "  ('learned', 'orange', 'PICO (Ours)'),\n",
    "  ('baseline', 'gray', 'Non-Adaptive (Baseline)'),\n",
    "  ('mae', 'red', 'Perceptual Similarity (Baseline)')\n",
    "]\n",
    "for model_name, color, label in configs:\n",
    "  plt.errorbar(\n",
    "    np.array(mets_of_model[model_name][x_key]), \n",
    "    mets_of_model[model_name][y_key], \n",
    "    mets_of_model[model_name]['%s_stderr' % y_key], \n",
    "    color=color,\n",
    "    marker='o', \n",
    "    capsize=2,\n",
    "    label=label\n",
    "  )\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9v58CTfl8jTc"
   ],
   "name": "BigBiGAN TF Hub Demo",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "18191f128e1547c5909189eba3ab0f61": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "405b1bf50cc24b92876078b93617d7f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "408d0e43998a4d1082d56384485de36f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_405b1bf50cc24b92876078b93617d7f2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_62a04b8c36844bcfa0b68618b733f4b1",
       "value": " 5/5 [00:04&lt;00:00,  1.05 file/s]"
      }
     },
     "62a04b8c36844bcfa0b68618b733f4b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ac3f4dcf3c0b47518c3ec15d5f7f7053": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "bb4d454926ae4cfcbf549a5f513b6acd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bde33b1854eb488baf3a0afb40d3ce4d",
        "IPY_MODEL_408d0e43998a4d1082d56384485de36f"
       ],
       "layout": "IPY_MODEL_18191f128e1547c5909189eba3ab0f61"
      }
     },
     "bde33b1854eb488baf3a0afb40d3ce4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Dl Completed...: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ff663e41b31a477c85b9549ae7df97c9",
       "max": 5,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ac3f4dcf3c0b47518c3ec15d5f7f7053",
       "value": 5
      }
     },
     "ff663e41b31a477c85b9549ae7df97c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
